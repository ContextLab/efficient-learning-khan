{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:39.538116Z",
     "start_time": "2023-01-30T17:53:36.835178Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from tqdm.notebook import tqdm\n",
    "from umap import UMAP\n",
    "from wordcloud import WordCloud, get_single_color_func\n",
    "\n",
    "from khan_helpers import Experiment\n",
    "from khan_helpers.constants import (\n",
    "    BOS_LECTURE_COLOR,\n",
    "    BOS_QUESTION_COLOR, \n",
    "    EMBS_DIR, \n",
    "    FIG_DIR, \n",
    "    FONTS_DIR,\n",
    "    FORCES_LECTURE_COLOR,\n",
    "    FORCES_QUESTION_COLOR,\n",
    "    GENERAL_QUESTION_COLOR,\n",
    "    MODELS_DIR,\n",
    "    RAW_DIR,\n",
    "    TRAJS_DIR,\n",
    "    WORDLE_COLORS\n",
    ")\n",
    "from khan_helpers.functions import (\n",
    "    correlation_exp, \n",
    "    interp_lecture,\n",
    "    multicol_display, \n",
    "    rbf_sum, \n",
    "    show_source\n",
    ")\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Circle\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define/inspect some functions & classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constructing knowledge maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:39.569536Z",
     "start_time": "2023-01-30T17:53:39.539162Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_source(correlation_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:39.574616Z",
     "start_time": "2023-01-30T17:53:39.570504Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_source(rbf_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:39.580054Z",
     "start_time": "2023-01-30T17:53:39.576186Z"
    }
   },
   "outputs": [],
   "source": [
    "def construct_knowledge_map(\n",
    "    participant, \n",
    "    lecture, \n",
    "    quiz, \n",
    "    map_grid, \n",
    "    rbf_width, \n",
    "    rbf_metric='euclidean'\n",
    "):\n",
    "    assert isinstance(quiz, int), \"Must select data from a single question set\"\n",
    "    lec_keys = {1: 'forces', 2: 'bos'}\n",
    "    # coerce lecture arg type\n",
    "    if hasattr(lecture, '__iter__') and not isinstance(lecture, str):\n",
    "        lecture = list(lecture)\n",
    "    else:\n",
    "        if isinstance(lecture, int):\n",
    "            lecture = lec_keys[lecture]\n",
    "        lecture = [lecture]\n",
    "    \n",
    "    map_vertices = map_grid.reshape(map_grid.shape[0] * map_grid.shape[1], 2)\n",
    "    quiz_data = participant.get_data(lecture=lecture, quiz=quiz)\n",
    "    qids_seen = quiz_data['qID']\n",
    "    qids_correct = quiz_data.loc[quiz_data['accuracy'] == 1, 'qID']\n",
    "    qembs_seen = questions_embeddings[qids_seen - 1]\n",
    "    qembs_correct = questions_embeddings[qids_correct - 1]\n",
    "    \n",
    "    _weights_map = rbf_sum(obs_coords=qembs_seen,\n",
    "                           pred_coords=map_vertices,\n",
    "                           width=rbf_width,\n",
    "                           metric=rbf_metric)\n",
    "    weights_map = _weights_map / _weights_map.max()\n",
    "    \n",
    "    raw_map = rbf_sum(obs_coords=qembs_correct,\n",
    "                      pred_coords=map_vertices,\n",
    "                      width=rbf_width,\n",
    "                      metric=rbf_metric)\n",
    "    raw_map /= _weights_map.max()\n",
    "    \n",
    "    return (raw_map / weights_map).reshape(map_grid.shape[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and plotting wordles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:39.584242Z",
     "start_time": "2023-01-30T17:53:39.581151Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_word_weights(topic_proportions, reference_data, topic_model):\n",
    "    ndim_in = topic_proportions.ndim\n",
    "    topic_proportions = np.atleast_2d(topic_proportions)\n",
    "    \n",
    "    word_weights = np.dot(topic_proportions, topic_model.components_)\n",
    "    ref_weights = np.dot(reference_data, topic_model.components_)\n",
    "    \n",
    "    word_weights -= ref_weights.mean(axis=0)\n",
    "\n",
    "    word_weights -= word_weights.min(axis=1, keepdims=True)\n",
    "    word_weights /= word_weights.max(axis=1, keepdims=True)\n",
    "\n",
    "    if ndim_in == 1:\n",
    "        word_weights = word_weights.squeeze()\n",
    "    \n",
    "    return word_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:39.590553Z",
     "start_time": "2023-01-30T17:53:39.585594Z"
    }
   },
   "outputs": [],
   "source": [
    "class InterpColorFunc:\n",
    "    def __init__(\n",
    "        self, \n",
    "        forces_weights, \n",
    "        bos_weights, \n",
    "        forces_color=None, \n",
    "        bos_color=None, \n",
    "        mid_color=None, \n",
    "        cmap=None, \n",
    "        n_colors=500\n",
    "    ):\n",
    "        self.forces_weights = forces_weights\n",
    "        self.bos_weights = bos_weights\n",
    "        if isinstance(cmap, (mpl.colors.Colormap, sns.palettes._ColorPalette)):\n",
    "            self.cmap = cmap\n",
    "            if any(\n",
    "                arg is not None for arg in (forces_color, bos_color, mid_color)\n",
    "            ):\n",
    "                warnings.warn('`forces_color`, `bos_color`, and `mid_color` '\n",
    "                              'arguments are ignored when passing a `cmap`')\n",
    "        elif cmap is None:\n",
    "            if forces_color is None or bos_color is None:\n",
    "                raise ValueError('must pass either `cmap` or both '\n",
    "                                 '`forces_color` and `bos_color`')\n",
    "            elif mid_color is None:\n",
    "                colors = [mpl.colors.to_rgb(forces_color), \n",
    "                          mpl.colors.to_rgb(bos_color)],\n",
    "            else:\n",
    "                colors = [mpl.colors.to_rgb(forces_color), \n",
    "                          mpl.colors.to_rgb(mid_color), \n",
    "                          mpl.colors.to_rgb(bos_color)]\n",
    "            self.cmap = LinearSegmentedColormap.from_list('WordleInterpCmap', \n",
    "                                                          colors=colors, \n",
    "                                                          N=n_colors)\n",
    "        else:\n",
    "            raise TypeError('bad cmap arg')\n",
    "        \n",
    "    def __call__(self, word, *args, **kwargs):\n",
    "        word_forces_weight = self.forces_weights[word]\n",
    "        word_bos_weight = self.bos_weights[word]\n",
    "        forces_weight_prop = word_forces_weight / (word_forces_weight + word_bos_weight)\n",
    "        \n",
    "        if isinstance(self.cmap, sns.palettes._ColorPalette):\n",
    "            cmap_index = len(self.cmap) - round(len(self.cmap) * forces_weight_prop)\n",
    "            r, g, b = [f\"{round(i * 100)}%\" for i in self.cmap[cmap_index]]\n",
    "        else:\n",
    "            cmap_index = self.cmap.N - round(self.cmap.N * forces_weight_prop)\n",
    "            r, g, b, a = self.cmap(cmap_index, bytes=True)\n",
    "        \n",
    "        return f\"rgb({r}, {g}, {b})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:39.595956Z",
     "start_time": "2023-01-30T17:53:39.591813Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_wordle(\n",
    "    textdict, \n",
    "    color_func=None, \n",
    "    mask=None, \n",
    "    stopwords=None, \n",
    "    border=False,\n",
    "    border_color='black',\n",
    "    border_width=1,\n",
    "    border_pad=1,\n",
    "    ax=None,\n",
    "    **kwargs\n",
    "):\n",
    "    if stopwords is not None:\n",
    "        if isinstance(stopwords, str):\n",
    "            stopwords = [stopwords]\n",
    "        for sw in stopwords:\n",
    "            textdict.pop(sw, None)\n",
    "            \n",
    "    wc = WordCloud(max_font_size=kwargs.pop('max_font_size', 50), \n",
    "                   collocations=False, \n",
    "                   background_color=kwargs.pop('background_color', 'white'), \n",
    "                   mask=mask, \n",
    "                   width=2000, \n",
    "                   height=1000,\n",
    "                   color_func=color_func,\n",
    "                   relative_scaling=kwargs.pop('relative_scaling', 1),\n",
    "                   **kwargs)\n",
    "    wc.generate_from_frequencies(textdict)\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    ax.imshow(wc, interpolation=\"bilinear\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    if border:\n",
    "        border = Circle((wc.width/2, wc.height/2), \n",
    "                        radius=wc.height/2 + border_pad, \n",
    "                        color=border_color, \n",
    "                        linewidth=border_width, \n",
    "                        fill=False, \n",
    "                        clip_on=False)\n",
    "        ax.add_patch(border)\n",
    "    \n",
    "    return wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:39.600784Z",
     "start_time": "2023-01-30T17:53:39.597363Z"
    }
   },
   "outputs": [],
   "source": [
    "KMAPS_FIG_DIR = FIG_DIR.joinpath('knowledge-maps-components')\n",
    "KMAPS_FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 15\n",
    "GRID_RESOLUTION = 100\n",
    "RBF_WIDTH = 50\n",
    "WORDLE_N_WORDS = 50\n",
    "WORDLE_FONT_PATH = FONTS_DIR.joinpath('Myriad Pro Regular.ttf')\n",
    "\n",
    "if not WORDLE_FONT_PATH.is_file():\n",
    "    warnings.warn(\"Unfortunately, Adobe's font license does not allow us to \"\n",
    "                  \"share the font file in this repository (though it's not \"\n",
    "                  \"hard to find online). If you want to reproduce the wordle \"\n",
    "                  \"figure with the same font we used (or a different one), \"\n",
    "                  \"add the file to the data/fonts/ folder and make sure its \"\n",
    "                  \"name matches the file name in this cell. Or, ignore this \"\n",
    "                  \"warning to use the wordcloud package's default font.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:39.609287Z",
     "start_time": "2023-01-30T17:53:39.601772Z"
    }
   },
   "outputs": [],
   "source": [
    "exp = Experiment()\n",
    "\n",
    "forces_windows = exp.forces_windows\n",
    "bos_windows = exp.bos_windows\n",
    "forces_timestamps = exp.forces_timestamps\n",
    "bos_timestamps = exp.bos_timestamps\n",
    "quiz_text_processsed = np.load(RAW_DIR.joinpath('quiz_text_processed.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T18:06:49.707086Z",
     "start_time": "2020-01-08T18:06:49.701143Z"
    }
   },
   "source": [
    "# Create 2D embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:41.274091Z",
     "start_time": "2023-01-30T17:53:39.610864Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Project text into 100 dimensions for better embedding\n",
    "corpus = np.concatenate((exp.forces_windows, exp.bos_windows))\n",
    "cv = CountVectorizer()\n",
    "lda = LatentDirichletAllocation(n_components=100, random_state=0)\n",
    "lda.fit(cv.fit_transform(corpus))\n",
    "\n",
    "forces_lecture_100d = interp_lecture(lda.transform(cv.transform(forces_windows)), \n",
    "                                     forces_timestamps)\n",
    "bos_lecture_100d = interp_lecture(lda.transform(cv.transform(bos_windows)), \n",
    "                                  bos_timestamps)\n",
    "questions_100d = lda.transform(cv.transform(quiz_text_processsed[:, 0]))\n",
    "\n",
    "# fit UMAP model to both lectures & all questions to embed in common space\n",
    "to_reduce = [forces_lecture_100d, bos_lecture_100d, questions_100d]\n",
    "\n",
    "# store incidces to separate embedding data later\n",
    "split_inds = np.cumsum([np.atleast_2d(vec).shape[0] for vec in to_reduce])[:2]\n",
    "\n",
    "# log-transform, concatenate along feature dimension\n",
    "to_reduce = np.log(np.vstack(to_reduce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:48.427524Z",
     "start_time": "2023-01-30T17:53:41.275248Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# UMAP uses numba to speed up various internal steps of the embedding\n",
    "# optimization by compiling repeated mathematical operations to machine\n",
    "# code. Because of this, embedding results may vary slightly across \n",
    "# different CPU architectures (e.g., x86 vs ARM) even when controlling \n",
    "# for all other factors (e.g., random state). \n",
    "\n",
    "# These embeddings were originally computed on AArch64 (Apple M1 Pro \n",
    "# chip, Docker container running Debian 13). If your system uses the\n",
    "# same processor type, the code below will recompute the embeddings from\n",
    "# scratch. Otherwise, it will load in the precomputed embeddings from\n",
    "# the fit UMAP model (originally saved in the cell below), which can be\n",
    "# inspected to verify they were derived from the same input data, \n",
    "# parameters, etc.\n",
    "\n",
    "if platform.machine() == 'aarch64':\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    reducer = UMAP(metric=correlation_exp, \n",
    "                   random_state=RANDOM_STATE, \n",
    "                   verbose=True).fit(to_reduce)\n",
    "else:\n",
    "    print(\"Loading precomputed embeddings (see comment above)\")\n",
    "    reducer =  np.load(MODELS_DIR.joinpath('fit_UMAP.npy'), \n",
    "                       allow_pickle=True).item()\n",
    "    \n",
    "embeddings =reducer.embedding_\n",
    "\n",
    "(forces_embedding, \n",
    " bos_embedding, \n",
    " questions_embeddings) = np.vsplit(embeddings, split_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:48.430693Z",
     "start_time": "2023-01-30T17:53:48.428692Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# save fit UMAP reducer and 2D embeddings\n",
    "# np.save(MODELS_DIR.joinpath('fit_UMAP'), reducer)\n",
    "# np.save(EMBS_DIR.joinpath('forces_lecture'), forces_embedding)\n",
    "# np.save(EMBS_DIR.joinpath('bos_lecture'), bos_embedding)\n",
    "# np.save(EMBS_DIR.joinpath('questions'), questions_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a 2D grid over the embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:48.443846Z",
     "start_time": "2023-01-30T17:53:48.431620Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# pad grid a little bit so extreme points aren't on edges of plot\n",
    "x_min, y_min = embeddings.min(axis=0) // 1 - 3\n",
    "x_max, y_max = embeddings.max(axis=0) // 1 + 3\n",
    "\n",
    "xs = np.linspace(x_min, x_max, GRID_RESOLUTION, endpoint=True)\n",
    "ys = np.linspace(y_min, y_max, GRID_RESOLUTION, endpoint=True)\n",
    "\n",
    "X, Y = np.meshgrid(xs, ys)\n",
    "xy_grid = np.empty((GRID_RESOLUTION, GRID_RESOLUTION, 2), dtype=np.float64)\n",
    "for (x_ix, y_ix), X_val in np.ndenumerate(X):\n",
    "    xy_grid[x_ix, y_ix] = (X_val, Y[x_ix, y_ix])\n",
    "    \n",
    "vertices = xy_grid.reshape(GRID_RESOLUTION**2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T22:00:33.001943Z",
     "start_time": "2020-02-24T22:00:32.994768Z"
    }
   },
   "source": [
    "# Recover topic vectors for some sample coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:51.248600Z",
     "start_time": "2023-01-30T17:53:48.445277Z"
    },
    "code_folding": [],
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# choose some locations for displaying word clouds\n",
    "wordle_coords = np.array([[-1, -8], [9, 3], [20, 6]])\n",
    "\n",
    "# inverse-transform coordinates into original topic space\n",
    "# (see comment above re: CPU architecture check for recomputing inverse \n",
    "# transform data vs loading precomputed data)\n",
    "if platform.machine() == 'aarch64':\n",
    "    np.random.seed(reducer.transform_seed)\n",
    "    wordle_vectors = np.array([reducer.inverse_transform(coord[None, :]) \n",
    "                               for coord in wordle_coords], \n",
    "                              dtype=np.float64).squeeze()\n",
    "    # np.save(TRAJS_DIR.joinpath('wordle_vectors'), wordle_vectors)\n",
    "else:\n",
    "    print(\"Loading precomputed wordle topic vecrors (see comment above)\")\n",
    "    wordle_vectors = np.load(TRAJS_DIR.joinpath('wordle_vectors.npy'))\n",
    "\n",
    "# undo log-transform & normalize\n",
    "wordle_vectors = np.exp(wordle_vectors)\n",
    "wordle_vectors /= wordle_vectors.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct knowledge maps from memory traces for embedded lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:51.662697Z",
     "start_time": "2023-01-30T17:53:51.249847Z"
    }
   },
   "outputs": [],
   "source": [
    "maps_arr = np.empty((3, len(exp.participants), GRID_RESOLUTION, GRID_RESOLUTION), \n",
    "                    dtype=np.float64)\n",
    "\n",
    "pbar = tqdm(total=len(exp.participants)*3, leave=False)\n",
    "for quiz in range(3):\n",
    "    store_key = f'forces_bos_quiz{quiz + 1}'\n",
    "    for i, p in enumerate(exp.participants):\n",
    "        # known values are knowledge traces for BOTH lectures\n",
    "        kmap = construct_knowledge_map(p,\n",
    "                                       lecture=('forces', 'bos', 'general'),\n",
    "                                       quiz=quiz,\n",
    "                                       map_grid=xy_grid,\n",
    "                                       rbf_width=RBF_WIDTH,\n",
    "                                       rbf_metric='euclidean')\n",
    "        p.store_kmap(kmap, store_key)\n",
    "        maps_arr[quiz, i] = kmap\n",
    "        pbar.update()\n",
    "        \n",
    "    # store average in avg participant\n",
    "    exp.avg_participant.store_kmap(maps_arr[quiz].mean(axis=0), store_key)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:51.839887Z",
     "start_time": "2023-01-30T17:53:51.663784Z"
    }
   },
   "outputs": [],
   "source": [
    "# save updated participant objects\n",
    "# exp.save_participants(allow_overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:51.845456Z",
     "start_time": "2023-01-30T17:53:51.840894Z"
    }
   },
   "outputs": [],
   "source": [
    "# uniformly shift coordinates to line up with heatmap bounds for plotting\n",
    "shifted_inds = np.append(split_inds, \n",
    "                         [split_inds[-1] + len(questions_embeddings), \n",
    "                          split_inds[-1] + len(questions_embeddings) + len(wordle_coords)])\n",
    "coords = np.vstack((embeddings, wordle_coords, vertices))\n",
    "coords_shifted = coords - coords.min(axis=0)\n",
    "coords_shifted /= (coords_shifted.max(axis=0) / GRID_RESOLUTION)\n",
    "(\n",
    "    forces_shifted, \n",
    "    bos_shifted, \n",
    "    questions_shifted, \n",
    "    wordle_coords_shifted, \n",
    "    _\n",
    ") = np.vsplit(coords_shifted, shifted_inds)\n",
    "\n",
    "# make sure split happened at correct indices\n",
    "assert len(forces_shifted) == len(forces_embedding)\n",
    "assert len(bos_shifted) == len(bos_embedding)\n",
    "assert len(questions_shifted) == len(questions_embeddings)\n",
    "assert len(wordle_coords_shifted) == len(wordle_coords)\n",
    "\n",
    "ff_qs_shifted = questions_shifted[:15]\n",
    "bos_qs_shifted = questions_shifted[15:30]\n",
    "gen_qs_shifted = questions_shifted[30:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-15T20:12:30.542744Z",
     "start_time": "2020-03-15T20:12:30.533159Z"
    }
   },
   "source": [
    "# Plot knowledge and learning maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:52.048427Z",
     "start_time": "2023-01-30T17:53:51.846727Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context('paper', font_scale=1.1):\n",
    "    cmap = 'bone'\n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(14, 4)\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        # knowledge estimate heatmap\n",
    "        kmap = exp.avg_participant.get_kmap(f'forces_bos_quiz{i + 1}')\n",
    "        sns.heatmap(kmap, \n",
    "                    vmin=0, \n",
    "                    vmax=1, \n",
    "                    cmap=cmap, \n",
    "                    xticklabels=[], \n",
    "                    yticklabels=[], \n",
    "                    cbar=False, \n",
    "                    ax=ax)            \n",
    "        ax.collections[0].remove()\n",
    "        ax.imshow(kmap,\n",
    "                  vmin=0,\n",
    "                  vmax=1,\n",
    "                  aspect='auto',\n",
    "                  cmap=cmap,\n",
    "                  interpolation='bilinear')\n",
    "        # Four Fundamental Forces quiz questions\n",
    "        ax.scatter(ff_qs_shifted[:, 0],\n",
    "                   ff_qs_shifted[:, 1],\n",
    "                   c=FORCES_QUESTION_COLOR,\n",
    "                   marker='o',\n",
    "                   s=50,\n",
    "                   zorder=2)\n",
    "        # Birth of Stars quiz questions\n",
    "        ax.scatter(bos_qs_shifted[:, 0], \n",
    "                   bos_qs_shifted[:, 1], \n",
    "                   c=BOS_QUESTION_COLOR, \n",
    "                   marker='o', \n",
    "                   s=50, \n",
    "                   zorder=2)\n",
    "        # general physics knowledge quiz questions\n",
    "        ax.scatter(gen_qs_shifted[:, 0],\n",
    "                   gen_qs_shifted[:, 1],\n",
    "                   c=GENERAL_QUESTION_COLOR,\n",
    "                   marker='o',\n",
    "                   s=50,\n",
    "                   zorder=2)\n",
    "        # Four Fundamental Forces lecture trajectory\n",
    "        if i > 0:\n",
    "            ax.plot(forces_shifted[:, 0], \n",
    "                    forces_shifted[:, 1], \n",
    "                    c=FORCES_LECTURE_COLOR,\n",
    "                    linestyle='--', \n",
    "                    linewidth=2, \n",
    "                    zorder=1)\n",
    "            # Birth of Stars lecture trajectory\n",
    "            if i > 1:\n",
    "                ax.plot(bos_shifted[:, 0], \n",
    "                        bos_shifted[:, 1], \n",
    "                        c=BOS_LECTURE_COLOR,\n",
    "                        linestyle='--',\n",
    "                        linewidth=2, \n",
    "                        zorder=1)\n",
    "                \n",
    "        # wordle coordinates\n",
    "        for coord, color in zip(wordle_coords_shifted, WORDLE_COLORS):\n",
    "            ax.scatter(coord[0], coord[1], c=color, marker='*', s=200)\n",
    "\n",
    "        ax.set_title(f'Quiz {i + 1}', fontsize=20, fontweight='semibold')\n",
    "        # undo automatic y-axis inversion from sns.heatmap\n",
    "        ax.invert_yaxis()\n",
    "    \n",
    "    axes[0].set_ylabel('Knowledge', \n",
    "                       fontsize=20, \n",
    "                       fontweight='semibold', \n",
    "                       fontstyle='italic')\n",
    "    \n",
    "    plt.tight_layout() \n",
    "#     plt.savefig(KMAPS_FIG_DIR.joinpath('knowledge_maps.pdf'), \n",
    "#                 dpi=1000, \n",
    "#                 bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:52.232020Z",
     "start_time": "2023-01-30T17:53:52.049357Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context('paper', font_scale=1.1):\n",
    "    cmap = 'bone'\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(9, 4)\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        # learning estimate heatmap\n",
    "        before = exp.avg_participant.get_kmap(f'forces_bos_quiz{i + 1}')\n",
    "        after = exp.avg_participant.get_kmap(f'forces_bos_quiz{i + 2}')\n",
    "        learning_map = after - before\n",
    "        sns.heatmap(learning_map, \n",
    "                    vmin=-0.2, \n",
    "                    vmax=0.5, \n",
    "                    cmap=cmap, \n",
    "                    xticklabels=[], \n",
    "                    yticklabels=[], \n",
    "                    cbar=False, \n",
    "                    ax=ax)\n",
    "        ax.collections[0].remove()\n",
    "        ax.imshow(learning_map, \n",
    "                  vmin=-0.2, \n",
    "                  vmax=0.5,\n",
    "                  aspect='auto', \n",
    "                  cmap=cmap, \n",
    "                  interpolation='bilinear')\n",
    "        # Four Fundamental Forces quiz questions\n",
    "        ax.scatter(ff_qs_shifted[:, 0], \n",
    "                   ff_qs_shifted[:, 1], \n",
    "                   c=FORCES_QUESTION_COLOR, \n",
    "                   marker='o', \n",
    "                   s=50,\n",
    "                   zorder=2)\n",
    "        # Birth of Stars quiz questions\n",
    "        ax.scatter(bos_qs_shifted[:, 0], \n",
    "                   bos_qs_shifted[:, 1], \n",
    "                   c=BOS_QUESTION_COLOR, \n",
    "                   marker='o', \n",
    "                   s=50,\n",
    "                   zorder=2)\n",
    "        # general physics knowledge quiz questions\n",
    "        ax.scatter(gen_qs_shifted[:, 0], \n",
    "                   gen_qs_shifted[:, 1], \n",
    "                   c=GENERAL_QUESTION_COLOR, \n",
    "                   marker='o', \n",
    "                   s=50,\n",
    "                   zorder=2)\n",
    "        # Four Fundamental Forces lecture trajectory\n",
    "        if i == 0:\n",
    "            ax.plot(forces_shifted[:, 0],\n",
    "                    forces_shifted[:, 1],\n",
    "                    c=FORCES_LECTURE_COLOR,\n",
    "                    linestyle='--', \n",
    "                    linewidth=2, \n",
    "                    zorder=1)\n",
    "        # Birth of Stars lecture trajectory\n",
    "        else:\n",
    "            ax.plot(bos_shifted[:, 0],\n",
    "                    bos_shifted[:, 1],\n",
    "                    c=BOS_LECTURE_COLOR,\n",
    "                    linestyle='--',\n",
    "                    linewidth=2, \n",
    "                    zorder=1)\n",
    "            \n",
    "        # wordle coordinates\n",
    "        for coord, color in zip(wordle_coords_shifted, WORDLE_COLORS):\n",
    "            ax.scatter(coord[0], coord[1], c=color, marker='*', s=200)\n",
    "\n",
    "        ax.set_title(fr'Quiz {i + 1} $\\rightarrow$ {i + 2}', \n",
    "                     fontsize=20, \n",
    "                     fontweight='semibold')\n",
    "        # undo automatic y-axis inversion from sns.heatmap\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "    axes[0].set_ylabel('Learning', \n",
    "                       fontsize=20, \n",
    "                       fontweight='semibold', \n",
    "                       fontstyle='italic')\n",
    "\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(KMAPS_FIG_DIR.joinpath('learning_maps.pdf'), \n",
    "#                 dpi=1000, \n",
    "#                 bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create shared colorbar for knowldge & learning maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:52.366813Z",
     "start_time": "2023-01-30T17:53:52.233210Z"
    }
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context('talk', font_scale=1.1):   \n",
    "    fig, cax1 = plt.subplots(1, figsize=(10, 0.75))\n",
    "    \n",
    "    norm = mpl.colors.Normalize()\n",
    "    mappable = mpl.cm.ScalarMappable(norm=norm, cmap='bone')\n",
    "    plt.colorbar(mappable, orientation='horizontal', cax=cax1)\n",
    "    \n",
    "    cax1.text(0.5, 1.7, \n",
    "              'p(knowledge)', \n",
    "              transform=cax1.transAxes, \n",
    "              fontsize='x-large', \n",
    "              fontstyle='italic',\n",
    "              va='bottom', \n",
    "              ha='center')\n",
    "    \n",
    "    cax2 = cax1.twiny()\n",
    "    cax2.set_xlim(-0.2, 0.5)\n",
    "    cax2.set_xticks(np.arange(-0.2, 0.6, 0.1))\n",
    "    \n",
    "    cax2.text(0.5, -0.7, \n",
    "              '$\\mathit{\\Delta}$ p(knowledge)', \n",
    "              transform=cax2.transAxes, \n",
    "              fontsize='x-large', \n",
    "              fontstyle='italic',\n",
    "              va='top', \n",
    "              ha='center')\n",
    "    \n",
    "    cax1.tick_params(labeltop=True, bottom=False, labelbottom=False, labelsize='large', length=0)\n",
    "    cax2.tick_params(top=False, labeltop=False, labelbottom=True, labelsize='large', length=0, pad=6)\n",
    "    \n",
    "#     plt.savefig(KMAPS_FIG_DIR.joinpath('knowledge-learning-maps-colorbar.pdf'), bbox_inches='tight', dpi=1000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create wordles for sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:53.094845Z",
     "start_time": "2023-01-30T17:53:52.367974Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulary = cv.get_feature_names_out()\n",
    "\n",
    "# get each word's total weight across all timepoints of each lecture\n",
    "forces_weightsum = np.dot(forces_lecture_100d, lda.components_).sum(axis=0)\n",
    "forces_wordweights = dict(zip(vocabulary, forces_weightsum))\n",
    "bos_weightsum = np.dot(bos_lecture_100d, lda.components_).sum(axis=0)\n",
    "bos_wordweights = dict(zip(vocabulary, bos_weightsum))\n",
    "\n",
    "# get weights over corpus words for each sample location's topic vector\n",
    "reference_data = np.concatenate((forces_lecture_100d, \n",
    "                                 bos_lecture_100d, \n",
    "                                 questions_100d))\n",
    "coords_wordweights = get_word_weights(wordle_vectors, reference_data, lda)\n",
    "\n",
    "# create a colormap by linearly interpolating between the two lectures' \n",
    "# colors. Use question colors as waypoints to increase lightness.\n",
    "cmap = LinearSegmentedColormap.from_list('WordleInterpCmap',\n",
    "                                         [FORCES_LECTURE_COLOR,\n",
    "                                          FORCES_QUESTION_COLOR,\n",
    "                                          BOS_QUESTION_COLOR,\n",
    "                                          BOS_LECTURE_COLOR],\n",
    "                                         N=100)\n",
    "# create a callable that will return a color for a given word in the \n",
    "# vocabulary based on its relative weight in the two lectures\n",
    "color_func = InterpColorFunc(forces_weights=forces_wordweights, \n",
    "                             bos_weights=bos_wordweights, \n",
    "                             cmap=cmap)\n",
    "\n",
    "if WORDLE_FONT_PATH.is_file():\n",
    "    font_path = str(WORDLE_FONT_PATH)\n",
    "else:\n",
    "    font_path = None\n",
    "\n",
    "fig, axarr =  plt.subplots(1, len(wordle_coords))\n",
    "fig.set_size_inches(24, 8)\n",
    "\n",
    "for i, coords in enumerate(coords_wordweights):\n",
    "    weights_dict = dict(zip(vocabulary, coords))\n",
    "    wc = plot_wordle(weights_dict, \n",
    "                     color_func=color_func, \n",
    "                     mask=exp.wordle_mask,\n",
    "                     border=True,\n",
    "                     border_color=WORDLE_COLORS[i],\n",
    "                     border_width=7,\n",
    "                     border_pad=2,\n",
    "                     ax=axarr[i], \n",
    "                     random_state=0,\n",
    "                     max_words=WORDLE_N_WORDS,\n",
    "                     relative_scaling=1,\n",
    "                     mode='RGBA',\n",
    "                     font_path=font_path,\n",
    "                     max_font_size=90,\n",
    "                     background_color=None)\n",
    "    \n",
    "#     with open(KMAPS_FIG_DIR.joinpath(f'wordle{i+1}.svg'), 'w') as f:\n",
    "#         f.write(wc.to_svg(embed_font=False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create colorbar for wordles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T17:53:53.132327Z",
     "start_time": "2023-01-30T17:53:53.095726Z"
    }
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context('talk'):   \n",
    "    fig, cax = plt.subplots(1, figsize=(0.5, 8))\n",
    "    \n",
    "    norm = mpl.colors.Normalize()\n",
    "    mappable = mpl.cm.ScalarMappable(norm=norm, cmap=cmap.reversed())\n",
    "    plt.colorbar(mappable, cax=cax)\n",
    "    \n",
    "    cax.text(0.5, 1.01, \n",
    "             'Four\\nFundamental\\nForces', \n",
    "             transform=cax.transAxes, \n",
    "             fontsize='large', \n",
    "             va='bottom', \n",
    "             ha='center')\n",
    "    cax.text(0.5, -0.02, \n",
    "             'Birth of\\nStars', \n",
    "             transform=cax.transAxes, \n",
    "             fontsize='large', \n",
    "             va='top', \n",
    "             ha='center')\n",
    "    cax.tick_params(right=False, labelright=False)\n",
    "#     plt.savefig(KMAPS_FIG_DIR.joinpath('wordle-colorbar.pdf'), bbox_inches='tight', dpi=1000)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "notify_time": "30",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
